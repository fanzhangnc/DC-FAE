{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np  # NumPy for numerical operations\n",
    "from sklearn.metrics import average_precision_score  # Calculate average precision score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # PyTorch functions\n",
    "import tqdm  # Progress bar library\n",
    "import torchvision.transforms as transforms  # Image transformation methods\n",
    "from torchvision.transforms.functional import to_pil_image  # Convert tensor to PIL image\n",
    "from torchvision.utils import make_grid  # Create grid of images\n",
    "\n",
    "# Insert custom paths into system path\n",
    "sys.path.insert(0, '/root/autodl-tmp/SL-KD')\n",
    "sys.path.insert(0, '/root/autodl-tmp/SL-KD/models/stylegan2')\n",
    "\n",
    "# Local application imports\n",
    "from models.dataset import dataset_dict  # Dataset dictionary containing different datasets\n",
    "from models.decoder import StyleGANDecoder  # StyleGAN decoder for image generation\n",
    "from models.e4e.psp_encoders import Encoder4Editing  # Encoder model for generating w\n",
    "from models.ops import load_network, age2group  # Network loading and age-group conversion\n",
    "from models.ops.loggerx import LoggerX  # Logging tool\n",
    "from models.modules import Classifier  # Classifier for attributes and age classification\n",
    "\n",
    "# Set the CUDA device to GPU 0\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Disable gradient calculation\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "# Auto-reload modules in Jupyter Notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set precision for printing tensors and disable scientific notation\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configuration\n",
    "img_size = 256  # Image size\n",
    "bs = 64  # Batch size\n",
    "\n",
    "# Normalization for image preprocessing\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.5, 0.5, 0.5],\n",
    "    std=[0.5, 0.5, 0.5],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Compose transformations for training and testing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "data_root_celeba = '/root/autodl-tmp/DATASET/celeba/img_align_celeba_ffhq'\n",
    "data_root_ffhq = '/root/autodl-tmp/DATASET/FFHQ/images256x256'\n",
    "\n",
    "# CelebA dataset\n",
    "dataset_type_celeba = dataset_dict['CelebA']\n",
    "test_celeba_loader = torch.utils.data.DataLoader(\n",
    "    dataset_type_celeba(data_root_celeba, img_size=img_size, split='test', transform=test_transform),\n",
    "    batch_size=bs,\n",
    "    shuffle=False,  # No shuffling for test set\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "train_celeba_loader = torch.utils.data.DataLoader(\n",
    "    dataset_type_celeba(data_root_celeba, img_size=img_size, split='train', transform=train_transform),\n",
    "    batch_size=bs,\n",
    "    shuffle=True,  # Shuffle for better generalization\n",
    "    drop_last=True,  # Drop last incomplete batch\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "# FFHQ dataset\n",
    "dataset_type_ffhq = dataset_dict['FFHQAge']\n",
    "train_ffhq_loader = torch.utils.data.DataLoader(\n",
    "    dataset_type_ffhq(data_root_ffhq, img_size=img_size, split='train', transform=train_transform),\n",
    "    batch_size=bs,\n",
    "    shuffle=True,  # Shuffle for better generalization\n",
    "    drop_last=True,  # Drop last incomplete batch\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "test_ffhq_loader = torch.utils.data.DataLoader(\n",
    "    dataset_type_ffhq(data_root_ffhq, img_size=img_size, split='test', transform=test_transform),\n",
    "    batch_size=bs,\n",
    "    shuffle=False,  # No shuffling for test set\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "mem_ffhq_loader = torch.utils.data.DataLoader(\n",
    "    dataset_type_ffhq(data_root_ffhq, img_size=img_size, split='train', transform=test_transform),\n",
    "    batch_size=bs,\n",
    "    num_workers=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Focal Loss definition\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets, weights):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # prevents nans when probability is 0\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        # Apply sample weights\n",
    "        F_loss = F_loss * weights\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            return F_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_attributes = 40\n",
    "P_T = torch.tensor([0.5] * num_attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_weights(labels, P_T):\n",
    "    batch_size, num_attributes = labels.shape\n",
    "    weights = torch.zeros_like(labels)\n",
    "\n",
    "    for a in range(num_attributes):\n",
    "        P_B_a = labels[:, a].mean().item()\n",
    "\n",
    "        if P_B_a > P_T[a]:  # Over-represented class\n",
    "            positive_indices = (labels[:, a] == 1).nonzero(as_tuple=True)[0]\n",
    "            num_to_keep = int(P_T[a] * batch_size)\n",
    "            keep_indices = positive_indices[torch.randperm(len(positive_indices))[:num_to_keep]]\n",
    "            weights[keep_indices, a] = 1\n",
    "            weights[labels[:, a] == 0, a] = P_T[a] / (1 - P_B_a)\n",
    "\n",
    "        else:  # Under-represented class\n",
    "            negative_indices = (labels[:, a] == 0).nonzero(as_tuple=True)[0]\n",
    "            num_to_keep = int((1 - P_T[a]) * batch_size)\n",
    "            keep_indices = negative_indices[torch.randperm(len(negative_indices))[:num_to_keep]]\n",
    "            weights[keep_indices, a] = 1\n",
    "            weights[labels[:, a] == 1, a] = P_T[a] / P_B_a\n",
    "\n",
    "    return weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Binary Classifier\n",
    "backbone = 'r50'  # `backbone = 'r34'` can be used for ResNet-34\n",
    "image_classifier = Classifier(backbone).cuda()\n",
    "\n",
    "# Logger settings\n",
    "logger = LoggerX(save_root=None, print_freq=100, enable_wandb=False)\n",
    "\n",
    "# Optimizer settings with a learning rate of 0.0001 and no weight decay\n",
    "optimizer = torch.optim.Adam(image_classifier.parameters(), lr=1e-4, weight_decay=0.00)\n",
    "\n",
    "# Training settings\n",
    "num_epochs = 10\n",
    "criterion = FocalLoss()\n",
    "n_iter = 0\n",
    "best_mAP = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}:')\n",
    "\n",
    "    for images, labels in train_celeba_loader:\n",
    "        # Move images and labels to GPU\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        # Set the classifier to training mode\n",
    "        image_classifier.train()\n",
    "\n",
    "        # Enable gradient calculation\n",
    "        with torch.autograd.set_grad_enabled(True):\n",
    "            # Forward pass\n",
    "            outs = image_classifier.forward_attr(images)[0]\n",
    "\n",
    "            # Compute sample weights\n",
    "            weights = compute_weights(labels, P_T)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outs, labels, weights)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Log the loss\n",
    "        logger.msg([loss], n_iter)\n",
    "        n_iter += 1\n",
    "\n",
    "        if n_iter % 1000 == 0:\n",
    "            print('Evaluating model...')\n",
    "\n",
    "            # Set the classifier to evaluation mode\n",
    "            image_classifier.eval()\n",
    "\n",
    "            # Initialize lists to store predictions and labels\n",
    "            all_preds, all_labels = [], []\n",
    "\n",
    "            # Disable gradient calculation\n",
    "            with torch.no_grad():\n",
    "                # Iterate over the test dataset\n",
    "                for images, labels in tqdm.tqdm(test_celeba_loader):\n",
    "                    # Move images and labels to GPU\n",
    "                    images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "                    # Forward pass and apply sigmoid to predictions\n",
    "                    preds = torch.sigmoid(image_classifier.forward_attr(images)[0])\n",
    "\n",
    "                    # Store predictions and labels\n",
    "                    all_preds.append(preds)\n",
    "                    all_labels.append(labels)\n",
    "\n",
    "                # Concatenate all predictions and labels and move to CPU\n",
    "                all_preds = torch.cat(all_preds, dim=0).cpu().numpy()\n",
    "                all_labels = torch.cat(all_labels, dim=0).cpu().numpy()\n",
    "\n",
    "                # Calculate average precision scores for each label and mean average precision (mAP)\n",
    "                average_precisions = [average_precision_score(all_labels[:, i], all_preds[:, i]) for i in range(40)]\n",
    "                mAP = np.mean(average_precisions)\n",
    "\n",
    "                # Print average precision scores and mAP\n",
    "                print('Average Precision Scores:', average_precisions)\n",
    "                print('Mean Average Precision (mAP):', mAP)\n",
    "\n",
    "                # Update the best mAP score\n",
    "                best_mAP = max(mAP, best_mAP)\n",
    "\n",
    "                # Save the model if the current mAP is the best\n",
    "                if best_mAP == mAP:\n",
    "                    print('Saving model...')\n",
    "                    torch.save(\n",
    "                        image_classifier.state_dict(),\n",
    "                        f'/root/autodl-tmp/SL-KD/data/focal_loss_{backbone}_{n_iter}.pth'\n",
    "                    )\n",
    "\n",
    "print('Training completed.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize Classifier\n",
    "backbone = 'r50'\n",
    "classifier_checkpoint = f'/root/autodl-tmp/SL-KD/data/focal_loss_{backbone}_19000.pth'\n",
    "\n",
    "# Initialize the classifier and ensure it is on GPU\n",
    "image_classifier = Classifier(backbone=backbone).cuda()\n",
    "\n",
    "# Load the classifier state dict from the checkpoint\n",
    "state_dict = torch.load(classifier_checkpoint, map_location='cpu')\n",
    "image_classifier.load_state_dict(load_network(state_dict))\n",
    "\n",
    "# Double-check the model is on GPU\n",
    "image_classifier = image_classifier.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Age classifier\n",
    "# Logger settings\n",
    "logger = LoggerX(save_root=None, print_freq=100)\n",
    "\n",
    "# Optimizer settings with a learning rate of 0.0001 and no weight decay\n",
    "optimizer = torch.optim.Adam(image_classifier.parameters(), lr=1e-4, weight_decay=0.00)\n",
    "\n",
    "# Training settings\n",
    "num_epochs = 10\n",
    "n_iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}:')\n",
    "\n",
    "    for images, labels in train_ffhq_loader:\n",
    "        # Move images and labels to GPU\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        # Set the classifier to training mode\n",
    "        image_classifier.train()\n",
    "\n",
    "        # Enable gradient calculation\n",
    "        with torch.autograd.set_grad_enabled(True):\n",
    "            # Forward pass\n",
    "            outs = image_classifier.forward_age(images)[0]\n",
    "            ordinal_labels = age2group(ordinal=True, groups=labels, age_group=7).float()\n",
    "            loss = F.binary_cross_entropy_with_logits(outs, ordinal_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Log the loss\n",
    "        logger.msg([loss, ], n_iter)\n",
    "        n_iter += 1\n",
    "\n",
    "        if n_iter % 1000 == 0:\n",
    "            print('Evaluating model...')\n",
    "\n",
    "            # Set the classifier to evaluation mode\n",
    "            image_classifier.eval()\n",
    "\n",
    "            # Initialize lists to store predictions and labels\n",
    "            all_preds, all_labels = [], []\n",
    "\n",
    "            # Disable gradient calculation for evaluation\n",
    "            with torch.no_grad():\n",
    "                # Iterate over the test dataset\n",
    "                for images, labels in tqdm.tqdm(test_ffhq_loader):\n",
    "                    # Move images and labels to GPU\n",
    "                    images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "                    # Forward pass and get predictions\n",
    "                    preds = image_classifier(images)[1]\n",
    "\n",
    "                    # Store predictions and labels\n",
    "                    all_preds.append(preds[:, -1])\n",
    "                    all_labels.append(labels)\n",
    "\n",
    "                # Concatenate all predictions and labels\n",
    "                all_preds = torch.cat(all_preds, dim=0)\n",
    "                all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "                # Compute masks for each class\n",
    "                masks = [(all_labels == i) for i in range(7)]\n",
    "\n",
    "                # Calculate the accuracy for each class\n",
    "                accuracies = [\n",
    "                    (all_preds == all_labels)[mask].float().mean(dim=0) for mask in masks\n",
    "                ]\n",
    "\n",
    "                # Stack all accuracies into a single tensor\n",
    "                accuracies_tensor = torch.stack(accuracies)\n",
    "\n",
    "                # Print the accuracy tensor\n",
    "                print(accuracies_tensor)\n",
    "\n",
    "print('Training completed.')\n",
    "\n",
    "# Define the save path\n",
    "save_path = os.path.join(\n",
    "    '/root/autodl-tmp/SL-KD/data',\n",
    "    f'focal_loss_{backbone}_age_{n_iter}.pth'\n",
    ")\n",
    "\n",
    "# Save the model state dictionary\n",
    "torch.save(image_classifier.state_dict(), save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define checkpoint paths\n",
    "stylegan2_checkpoint = '/root/autodl-tmp/SL-KD/data/ffhq.pkl'\n",
    "e4e_checkpoint = '/root/autodl-tmp/SL-KD/data/e4e_ffhq_encode.pt'\n",
    "classifier_checkpoint = '/root/autodl-tmp/SL-KD/data/focal_loss_r34_age_8410.pth'\n",
    "\n",
    "# Define output size\n",
    "output_size = 256\n",
    "\n",
    "# Initialize StyleGANDecoder\n",
    "G = StyleGANDecoder(\n",
    "    stylegan2_checkpoint,\n",
    "    start_from_latent_avg=False,\n",
    "    output_size=output_size\n",
    ")\n",
    "G = G.cuda().eval()\n",
    "\n",
    "# Initialize Encoder4Editing\n",
    "encoder = Encoder4Editing(\n",
    "    num_layers=50,\n",
    "    mode='ir_se',\n",
    "    stylegan_size=1024,\n",
    "    checkpoint_path=e4e_checkpoint\n",
    ")\n",
    "encoder = encoder.cuda().eval()\n",
    "\n",
    "# Initialize Classifier\n",
    "backbone = 'r34'\n",
    "image_classifier = Classifier(backbone=backbone).cuda()\n",
    "image_classifier.load_state_dict(\n",
    "    load_network(torch.load(classifier_checkpoint, map_location='cpu'))\n",
    ")\n",
    "image_classifier = image_classifier.cuda().eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate latent vectors and corresponding labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize lists to store all latents and predictions\n",
    "all_latents = []\n",
    "all_preds = []\n",
    "\n",
    "# Set models to evaluation mode\n",
    "encoder.eval()\n",
    "image_classifier.eval()\n",
    "\n",
    "# Obtain latents\n",
    "for images, _ in tqdm.tqdm(mem_ffhq_loader):\n",
    "    images = images.cuda()\n",
    "    with torch.no_grad():\n",
    "        all_latents.append(encoder(images))\n",
    "\n",
    "# Concatenate all latents into a single tensor\n",
    "all_latents = torch.cat(all_latents, dim=0)\n",
    "\n",
    "# Obtain predictions\n",
    "for images, _ in tqdm.tqdm(mem_ffhq_loader):\n",
    "    images = images.cuda()\n",
    "    with torch.no_grad():\n",
    "        preds = image_classifier(images)[0].sigmoid()\n",
    "        all_preds.append(preds)\n",
    "\n",
    "# Concatenate all predictions into a single tensor\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "\n",
    "# Save latents and predictions with updated filenames\n",
    "torch.save(all_latents, '/root/autodl-tmp/SL-KD/data/ffhq_train_latents.pth')\n",
    "torch.save(all_preds, '/root/autodl-tmp/SL-KD/data/focal_loss_ffhq_train_preds.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Load latents and predictions\n",
    "all_latents = torch.load(\n",
    "    '/root/autodl-tmp/SL-KD/data/ffhq_train_latents.pth',\n",
    "    map_location='cpu'\n",
    ").cuda() + G.latent_avg\n",
    "\n",
    "all_preds = torch.load(\n",
    "    '/root/autodl-tmp/SL-KD/data/focal_loss_ffhq_train_preds.pth',\n",
    "    map_location='cpu'\n",
    ").cuda()\n",
    "\n",
    "# Select the indices and display the images and predictions\n",
    "indices = torch.arange(16)\n",
    "\n",
    "# Display the generated images\n",
    "generated_images = to_pil_image(make_grid(G(all_latents[indices])).clamp(-1., 1.) * 0.5 + 0.5)\n",
    "display(generated_images)\n",
    "\n",
    "# Display the selected predictions\n",
    "display(all_preds[indices[:, None], [15, 20, 31]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.modules import FLOW\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "realnvp = FLOW(style_dim=G.style_dim, n_styles=G.n_styles, n_layer=10).cuda().eval()\n",
    "optimizer = torch.optim.AdamW(list(realnvp.parameters()), lr=0.0001, weight_decay=0.00)\n",
    "\n",
    "# Initialize logger\n",
    "logger = LoggerX(save_root=None, print_freq=10)\n",
    "\n",
    "# Set training parameters\n",
    "max_iter = 10000\n",
    "bs = 256\n",
    "\n",
    "# Training loop\n",
    "for n_iter in range(1, max_iter + 1):\n",
    "    # Sample random latents\n",
    "    indices = torch.randint(0, len(all_latents), (bs,))\n",
    "    latents = all_latents[indices]\n",
    "\n",
    "    realnvp.train()\n",
    "\n",
    "    # Enable gradient tracking\n",
    "    with torch.autograd.set_grad_enabled(True):\n",
    "        # Compute loss, log determinant of Jacobian, and other outputs\n",
    "        loss, logz, log_det_jacobian, _ = realnvp(latents)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Log the results\n",
    "    logger.msg([logz, log_det_jacobian, loss], n_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adatrans",
   "language": "python",
   "name": "adatrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ff0f43fc3f39160c2cc18cc2c3cb7265d766f19e8425068885695f0819092ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}